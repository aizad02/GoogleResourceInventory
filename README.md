# Google Resource Inventory

* This is not a Google product or software
* Use the new version in python. The old scripts stays in place for historic.

A script that extracts information from one, or more, GCP projects, that can be used for any kind of analysis. Its a inventory of your cloud.

Calling the collect.py program the process read and exports data to csv ou excel, you choose.

## Recommendations
- Use a Service Account that has ONLY read-only access, although this script does not change anything in the cloud, it's a good practice to give only the access needed.

## How to use
```bash
pip3 install -r requirements.yaml
./collect.py
```

Requirements file generated by pipreqs.

## Exporting Data
You can save the collect date to csv ou xls, by using the -o parameter. If ommited will assume the default csv. The files will going to be saved in ./output folder.
Example: Save both to csv and xls. 
```bash
./collect.py -o csv -o xls
```

## Limitating Resource
By using the parameters -r is possible to determine just a kind of resources to collect data. This parameters can be used multiple times.
Example: Collect data of gcs and gke only:
```bash
./collect.py -r gcs -r gke
```

## What is collected?
- Virtual Machines
- CloudSQL
- Functions
- GCS
- GKE
- Artifact Registry
- PubSub

## Questions
- Question: Why reading compute machines is slow?
  Response: During the process of reading compute machines the process also searchs in the monitoring metrics for the CPU usage of the machine.